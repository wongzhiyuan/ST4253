---
title: "Tutorial 9"
author: "Bharath S"
date: "2023-11-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load Libraries

```{r}
# Load necessary libraries
library(fpp3)
library(tidyverse)
library(imputeTS)
library(zoo)
library(forecast)
library(tsibble)
```

# Helper Functions

## Generate ARIMA Series

```{r - Utility fxns} 
set.seed(1231)
generate_arima_tsibble <- function(n, order, ar, ma, sd_noise) {
    # n: number of observations
    # order: order of the ARIMA model (p, d, q)
    # ar: auto-regressive parameters (vector)
    # ma: moving average parameters (vector)
    # sd_noise: standard deviation of the noise
    
    # Check and set AR and MA parameters based on order
    model_list <- list(order = order, sd = sd_noise)
    if (order[1] > 0) model_list$ar <- ar  # Include AR parameters if p > 0
    if (order[3] > 0) model_list$ma <- ma  # Include MA parameters if q > 0

    # Generate the ARIMA time series
    arima_series <- arima.sim(n = n, model = model_list)
    
    # Create a tsibble from the generated time series
    arima_tsibble <- as_tsibble(ts(arima_series))
    
    return(arima_tsibble)
}
```

## Function to drop observations

We drop the observations in 3 ways - 

 1. Random Dropping
 2. Chunked Dropping
 3. Thresholded Dropping

```{r}
drop_observations <- function(ts_data, fraction, mode = "random") {
    # ts_data: A tsibble with the time series data
    # fraction: Fraction of the observations to drop
    # mode: The mode of dropping observations - "random", "chunked", or "thresholded"

    # Calculate the number of observations to drop
    num_to_drop <- round(fraction * nrow(ts_data))

    if (mode == "random") {
        # Randomly select indices to drop
        drop_indices <- sample(nrow(ts_data), num_to_drop)
        ts_data[drop_indices, "value"] <- NA
    } else if (mode == "chunked") {
        # Compute indices to drop in chunks
        chunk_size <- max(1, num_to_drop) # Ensure at least one observation is dropped
        total_chunks <- ceiling(nrow(ts_data) / chunk_size)
        selected_chunk_start <- sample(nrow(ts_data), total_chunks, replace = FALSE)
        for (start in selected_chunk_start) {
            end <- min(nrow(ts_data), start + chunk_size - 1)
            ts_data[start:end, "value"] <- NA
            num_to_drop <- num_to_drop - (end - start + 1)
            if (num_to_drop <= 0) break
        }
    } else if (mode == "thresholded") {
        # Calculate thresholds for dropping top and bottom fractions
        lower_threshold <- quantile(ts_data[["value"]], fraction , na.rm = TRUE)
        upper_threshold <- quantile(ts_data[["value"]], 1 - fraction , na.rm = TRUE)

        # Identify indices where values fall outside the threshold range
        drop_indices <- which(ts_data[["value"]] < lower_threshold | ts_data[["value"]] > upper_threshold)
        selected_indices <- sample(drop_indices, min(num_to_drop, length(drop_indices)))
        ts_data[selected_indices, "value"] <- NA
    } else {
        stop("Unknown mode specified. Use 'random', 'chunked', or 'thresholded'.")
    }
    
    return(ts_data)
}

```

## Estimate Parameters for a given time series dataset

```{r}
estimate_arima_params <- function(ts_data) {
  auto_fit <- auto.arima(ts_data, method="ML")
  
  # Extract AR and MA parameters
  ar_params <- auto_fit$coef[paste0("ar", seq(auto_fit$arma[1]))]
  ma_params <- auto_fit$coef[paste0("ma", seq(auto_fit$arma[2]))]
  
  return(list(order = arimaorder(auto_fit), ar = ar_params, ma = ma_params))
}

compute_forecast_horizon <- function(ts_data, order, ar, ma, h) {
  model <- Arima(ts_data$value, order = order, method="CSS")
  forecast_horizon <- forecast(model, h = h)
  return(forecast_horizon)
}
```

## Forecast framework function

This function calculates the parameters of an ARIMA given a list of datasets. It then returns the results, containing the forecast based on the estimated parameters, the true values, and the estimated parameters. 

```{r}
arima_forecast_framework <- function(datasets, order, ar, ma, h, true_test_data) {
  results <- list()
  
  for (i in seq_along(datasets)) {
    dataset <- datasets[[i]]
    
    # Compute forecast using true parameters
    forecast_true_params <- true_test_data
    
    # Estimate parameters and compute forecast
    estimated_params <- estimate_arima_params(dataset)
    forecast_estimated_params <- compute_forecast_horizon(dataset, estimated_params$order, estimated_params$ar, estimated_params$ma, h)
    
    # Store the results
    results[[i]] <- list(forecast_true_params = forecast_true_params,
                         forecast_estimated_params = forecast_estimated_params,
                         estimated_params = estimated_params)
  }
  
  return(results)
}
```

## Imputation Functions

We define helper functions for the imputation here:

 1. **Last Observation Carried Forward (LOCF)**: `impute_locf` function fills missing values with the last observed value prior to the gap.
 2. **Next Observation Carried Backward (NOCB)**: `impute_nocb` function imputes missing values with the next observation in the time series.
 3. **Moving Average**: `impute_ma` function replaces missing values with the moving average.
 4. **ARIMA**: `impute_arima` function employs the Kalman filter on an automatically fitted ARIMA model to impute missing data.
 5. **Linear Interpolation**: `impute_linear` function applies linear interpolation to fill in the gaps.
 6. **Spline Interpolation**: `impute_spline` function uses spline interpolation for imputing missing values, providing a smoother curve compared to linear interpolation.

```{r}
impute_locf <- function(ts){
  ts %>% mutate(value = na_locf(value, option = "locf"))
}

impute_nocb <- function(ts){
  ts %>% mutate(value = na_locf(value, option = "nocb"))
}

impute_ma <- function(ts){
  ts %>% mutate(value = na_ma(value))
}

impute_arima <- function(ts){
  ts %>% mutate(value = na_kalman(value, model = 'auto.arima'))
}

impute_linear <- function(ts){
  ts %>% mutate(value = na_interpolation(value, option = "linear"))
}

impute_spline <- function(ts){
  ts %>% mutate(value = na_interpolation(value, option = "spline"))
}
```

## Principal Helper Function

This function completes 1 round of tests for a single instance of a dataset and an imputation function. It then fits the datasets, computes the forecasts, and stores the forecasts and the estimated parameters of the ARIMA. 

```{r}
df_generator_helper <- function(impute_function, n, order, ar_param, ma_param, sd_noise, trial_number, fraction_missing = 0.2){

  arima_ts <- generate_arima_tsibble(n, order, ar_param, ma_param, sd_noise)
  arima_ts_train <- arima_ts[2:401,]
  arima_ts_test <- arima_ts[401:n,]

  modified_ts <- drop_observations(arima_ts_train, fraction_missing)
  thresholded_modified_ts<-drop_observations(arima_ts_train, fraction_missing,'thresholded')
  chunked_modified_ts<-drop_observations(arima_ts_train, fraction_missing,'chunked')
  
  adjusted_ts <- impute_function(modified_ts)
  adjusted_thresholded_ts <- impute_function(thresholded_modified_ts)
  adjusted_chunked_ts <- impute_function(chunked_modified_ts)
  
  dataset <- list(arima_ts_train, adjusted_ts, adjusted_thresholded_ts, adjusted_chunked_ts)
  forecast_results <- arima_forecast_framework(dataset,order,ar_param,ma_param,h=100,
                                               arima_ts_test)
  
  df <- tibble()
  labels <- c("Unchanged", "Random", "Threshold", "Chunks")
  count <- 1
  for (i in 1:length(forecast_results)){
    forecast_accuracy <- as_tibble(accuracy(forecast_results[[i]]$forecast_estimated_params, data = ))
    estimated_params <- forecast_results[[i]]$estimated_params  # Extract estimated_params
    
    # Combine accuracy data and estimated_params
    combined_data <- cbind(Type = labels[count], forecast_accuracy, Estimated_Order = I(list(estimated_params$order)), Estimated_AR = I(list(estimated_params$ar)), Estimated_MA = I(list(estimated_params$ma)), Trial_Number = trial_number)

    # Add to df
    if (nrow(df) == 0){
      df <- combined_data
    } else {
      df <- rbind(df, combined_data)
    }
    count <- count + 1
  }
  df
}
```

## Main Function

This function generates n runs for each imputation method, and returns the results in a single dataframe

```{r}
forecast_generate <-function(impute_function,tries){
  main<-data.frame()
  for (i in 1:tries){
    main<-rbind(main,df_generator_helper(impute_function,n, order, ar_param, ma_param, sd_noise, trial_number = i))
  }
  main
}
```

```{r}
# Assuming forecast_generate is a function that takes an imputation function and number of steps
# and returns a tsibble with forecasts

generate_and_label <- function(impute_func, method_name, steps) {
  forecast_data <- forecast_generate(impute_func, steps)
  forecast_data <- forecast_data %>% mutate(imputation_method = method_name)
  return(forecast_data)
}
```

# Simulation

## ARIMA Parameters

```{r}
# TS Params
n <- 500  # Number of observations
order <- c(1, 2, 1)  # ARIMA order (p, d, q)
ar_param <- 0.5  # AR parameter
ma_param <- -0.7  # MA parameter
sd_noise <- 0.1  # Standard deviation of noise
```

## Generate forecasts

```{r}
# Generate forecasts for each imputation method
na_ma_forecast_data <- generate_and_label(impute_ma, "ma", 50)
na_locf_forecast_data <- generate_and_label(impute_locf, "locf", 50)
na_nocb_forecast_data <- generate_and_label(impute_nocb, "nocb", 50)
na_arima_forecast_data <- generate_and_label(impute_arima, "arima", 50)
na_linear_forecast_data <- generate_and_label(impute_linear, "linear", 50)
na_spline_forecast_data <- generate_and_label(impute_spline, "spline", 50)
```

```{r}
# Join all datasets
all_forecasts <- bind_rows(
  na_ma_forecast_data,
  na_locf_forecast_data,
  na_nocb_forecast_data,
  na_linear_forecast_data,
  na_arima_forecast_data,
  na_spline_forecast_data
)
```

```{r}
# Initialize the new column with NA or an appropriate default value
all_forecasts$estimated_p <- NA 
all_forecasts$estimated_d <- NA 
all_forecasts$estimated_q <- NA 

for (i in 1:nrow(all_forecasts)) {
  all_forecasts$estimated_p[i] <- all_forecasts[i, "Estimated_Order"][[1]][1]
  all_forecasts$estimated_d[i] <- all_forecasts[i, "Estimated_Order"][[1]][2]
  all_forecasts$estimated_q[i] <- all_forecasts[i, "Estimated_Order"][[1]][3]
}

```

```{r}
# Initialize the new columns with NA or appropriate default values
all_forecasts$estimated_ar <- NA 
all_forecasts$estimated_ma <- NA 

for (i in 1:nrow(all_forecasts)) {
    # Extract the value from the "Estimated_AR" and "Estimated_MA" columns
    value_ar <- all_forecasts[i, "Estimated_AR"][[1]][1]
    value_ma <- all_forecasts[i, "Estimated_MA"][[1]][1]

    # Assign them to the new columns for the corresponding row
    all_forecasts$estimated_ar[i] <- value_ar
    all_forecasts$estimated_ma[i] <- value_ma
}
```

```{r}
all_forecasts %>%
  select(Type, RMSE, imputation_method, estimated_p, estimated_d, estimated_q, estimated_ar, estimated_ma) %>%
  mutate(across(c(RMSE, estimated_p, estimated_d, estimated_q, estimated_ar, estimated_ma), ~replace_na(., 0))) %>%
  mutate(param_diff = abs(estimated_p - order[1]) + abs(estimated_d - order[2]) + abs(estimated_q - order[3]) + abs(estimated_ar - ar_param) + abs(estimated_ma - ma_param) ) -> all_forecasts
```
# Analysis 

```{r fig.width=12, fig.height=6}
ggplot(all_forecasts, aes(x = Type, y = param_diff, fill = Type)) +
  geom_boxplot() +  # or geom_line(), depending on your data and what you're trying to illustrate
  facet_wrap(~ imputation_method) +
  labs(title = "Parameter Difference as a Function of Type, Faceted by Imputation Method",
       x = "Type",
       y = "Parameter Difference") +
  theme_bw()
```

```{r fig.width=12, fig.height=6}
ggplot(all_forecasts, aes(x = Type, y = RMSE, fill = Type)) +
  geom_boxplot() +
  facet_wrap(~imputation_method, scales = "free_y") +
  labs(title = "Comparison of RMSE by Type and Imputation Method",
       x = "Type",
       y = "RMSE") +
  theme_bw() +
  theme(legend.position = "none")
```



